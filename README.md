# ğŸ“„ PDF RAG Chatbot using Gemini Flash, FastAPI, React, and FAISS

A full-stack AI chatbot that answers questions from a PDF document using **Retrieval-Augmented Generation (RAG)**. The system extracts text using OCR, converts it into embeddings, stores them in a FAISS vector database, and uses **Gemini Flash** to generate accurate answers based on context.

---

## ğŸš€ Features

- ğŸ“„ Extracts text from PDF using OCR
- âœ‚ï¸ Splits text into chunks for efficient processing
- ğŸ§  Converts text into vector embeddings
- ğŸ—„ï¸ Stores embeddings in FAISS vector database
- ğŸ” Retrieves relevant chunks using cosine similarity
- ğŸ¤– Uses Gemini Flash to generate context-based answers
- ğŸŒ Full-stack web app using React + FastAPI
- ğŸ”’ Secure API key handling using `.env`

---

## ğŸ§  Architecture


User (React Frontend)
â†“
FastAPI Backend
â†“
Embedding Model (SentenceTransformers)
â†“
FAISS Vector Database
â†“
Retrieve relevant chunks
â†“
Gemini Flash LLM
â†“
Response returned to user


---

## ğŸ› ï¸ Tech Stack

### Frontend
- React.js
- Axios
- HTML/CSS

### Backend
- FastAPI
- Python
- FAISS (Vector Database)
- SentenceTransformers (Embeddings)
- Gemini Flash API

### AI / ML
- OCR (Tesseract / PyMuPDF)
- Embedding Model: all-MiniLM-L6-v2
- LLM: Gemini 2.5 Flash
- Vector Search: FAISS

---

## ğŸ“ Project Structure

```
pdf-rag-chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI server
â”‚   â”œâ”€â”€ chatbot.py          # RAG logic
â”‚   â”œâ”€â”€ vector.index        # FAISS vector database
â”‚   â”œâ”€â”€ chunks.pkl          # Text chunks
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env                # API key (not committed)
â”‚   â””â”€â”€ .gitignore
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js          # React UI
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

---

